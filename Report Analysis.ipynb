{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file(file):\n",
    "    with open(file, 'rb') as loaded_file:\n",
    "        return pickle.load(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_naive_opt = load_pickle_file(\"./optimization_log_Fixed_GRU_easy.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_optimization_top(opt_dict, index=0):\n",
    "    parsed_dict = defaultdict(lambda: defaultdict(lambda: dict()))\n",
    "    \n",
    "    def parse_key(key):\n",
    "        first_split = key.split(\", \")\n",
    "        embed = first_split[0].split(\":\")[1]\n",
    "        hidden = first_split[1].split(\":\")[1]\n",
    "        lr = first_split[2].split(\":\")[1]\n",
    "        return int(embed), int(hidden), float(lr)\n",
    "    \n",
    "    for key, value in opt_dict.items():\n",
    "        embed, hidden, lr = parse_key(key)\n",
    "        top = value[index]\n",
    "        parsed_dict[lr][hidden][embed] = top\n",
    "    \n",
    "    return parsed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_naive_opt_top_1 = parse_optimization_top1(cbow_naive_opt)\n",
    "print(cbow_naive_opt_top_1[0.001][56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframes(opt_dict):\n",
    "    largeDF = pd.DataFrame.from_dict(opt_dict[0.001])\n",
    "    midDF = pd.DataFrame.from_dict(opt_dict[0.0001])\n",
    "    smallDF = pd.DataFrame.from_dict(opt_dict[1e-05])\n",
    "    return smallDF, midDF, largeDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cbow_naive_df, mid_cbow_naive_df, large_cbow_naive_df = create_dataframes(cbow_naive_opt_top_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(dataframe):\n",
    "    cmap = sns.light_palette(\"red\", as_cmap=True)\n",
    "    sns.set_style('white')\n",
    "    hmap = sns.heatmap(dataframe,\n",
    "                cmap=cmap, \n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                annot=True,\n",
    "                fmt=\"0.3f\",\n",
    "                linewidths=0.5)\n",
    "\n",
    "    # [tick.set_text(\"{0:0.0f}\".format(float(tick.get_text()))) for tick in hmap.get_yticklabels()]\n",
    "    # format text labels\n",
    "    xticklabels = []\n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_text(\"{0:0.0f}\".format(float(item.get_text())))\n",
    "        xticklabels += [item]\n",
    "    yticklabels = []\n",
    "    for item in ax.get_yticklabels():\n",
    "        item.set_text(\"{0:0.0f}\".format(float(item.get_text())))\n",
    "        yticklabels += [item]\n",
    "\n",
    "    hmap.set_xticklabels(xticklabels)\n",
    "    hmap.set_yticklabels(yticklabels)\n",
    "\n",
    "    [tick.set_rotation(0) for tick in hmap.get_yticklabels()]\n",
    "    hmap.set(xlabel=\"Hidden Layer Dimension\", ylabel=\"Embedding Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(small_cbow_naive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(mid_cbow_naive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(large_cbow_naive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed files\n",
    "cbow_easy = (load_pickle_file(\"./results_cbow_naive_easy.p\"), \"CBOW Naive\")\n",
    "cbow_hard = (load_pickle_file(\"./results_cbow_naive_hard.p\"), \"CBOW Naive\")\n",
    "cbow_reg_easy = (load_pickle_file(\"./results_cbow_reg_easy.p\"), \"CBOW Regression\")\n",
    "cbow_reg_hard = (load_pickle_file(\"./results_cbow_reg_hard.p\"), \"CBOW Regression\")\n",
    "gru_easy = (load_pickle_file(\"./results_Fixed_GRU_easy_best_params_[300, 56, 0.0001].p\"), \"GRU\")\n",
    "gru_hard = (load_pickle_file(\"./results_Fixed_GRU_hard_best_params_[300, 56, 0.0001].p\"), \"GRU\")\n",
    "gru_reg_easy = (load_pickle_file(\"./results_gru_reg_easy_best_params_[350, 1024, 0.001].p\"), \"GRU Regression\")\n",
    "gru_reg_hard = (load_pickle_file(\"./results_gru_reg_hard_best_params_[350, 1024, 0.001].p\"), \"GRU Regression\")\n",
    "\n",
    "files_easy = [cbow_easy, cbow_reg_easy, gru_easy, gru_reg_easy]\n",
    "files_hard = [cbow_hard, cbow_reg_hard, gru_hard, gru_reg_hard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_df_for_key(lookup, key=\"top_1\"):\n",
    "    return pd.DataFrame(lookup[key])\n",
    "key = \"top_1\"\n",
    "\n",
    "plt.figure()\n",
    "axes = None\n",
    "\n",
    "for file_tup in files_easy:\n",
    "    file_df = create_df_for_key(file_tup[0])\n",
    "    if axes is None:\n",
    "        axes = file_df.plot(label=file_tup[1])\n",
    "    else:\n",
    "        file_df.plot(ax=axes, label=file_tup[1])\n",
    "        \n",
    "axes.set_xlabel(\"Epoch\")\n",
    "axes.set_ylabel(\"Accuracy Easy Dataset\")\n",
    "axes.legend([x[1] for x in files_easy],loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "axes.set_ylim(0, 1.1)\n",
    "axes.set_xlim(0, 29)\n",
    "axes.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x+1:0.0f}\"))\n",
    "axes.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x*100:0.0f}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "axes = None\n",
    "\n",
    "for file_tup in files_hard:\n",
    "    file_df = create_df_for_key(file_tup[0])\n",
    "    if axes is None:\n",
    "        axes = file_df.plot(label=file_tup[1])\n",
    "    else:\n",
    "        file_df.plot(ax=axes, label=file_tup[1])\n",
    "        \n",
    "axes.set_xlabel(\"Epoch\")\n",
    "axes.set_ylabel(\"Accuracy Hard Dataset\")\n",
    "axes.legend([x[1] for x in files_hard],loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "axes.set_ylim(0, 1.1)\n",
    "axes.set_xlim(0, 29)\n",
    "axes.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x+1:0.0f}\"))\n",
    "axes.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x*100:0.0f}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparisons Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_easy = (load_pickle_file(\"./results_cbow_naive_easy.p\"), \"CBOW Naive Preprocessed\")\n",
    "cbow_hard = (load_pickle_file(\"./results_cbow_naive_hard.p\"), \"CBOW Naive Preprocessed\")\n",
    "cbow_reg_easy = (load_pickle_file(\"./results_cbow_reg_easy.p\"), \"CBOW Regression Preprocessed\")\n",
    "cbow_reg_hard = (load_pickle_file(\"./results_cbow_reg_hard.p\"), \"CBOW Regression Preprocessed\")\n",
    "gru_easy = (load_pickle_file(\"./results_Fixed_GRU_easy_best_params_[300, 56, 0.0001].p\"), \"GRU Preprocessed\")\n",
    "gru_hard = (load_pickle_file(\"./results_Fixed_GRU_hard_best_params_[300, 56, 0.0001].p\"), \"GRU Preprocessed\")\n",
    "gru_reg_easy = (load_pickle_file(\"./results_gru_reg_easy_best_params_[350, 1024, 0.001].p\"), \"GRU Regression Preprocessed\")\n",
    "gru_reg_hard = (load_pickle_file(\"./results_gru_reg_hard_best_params_[350, 1024, 0.001].p\"), \"GRU Regression Preprocessed\")\n",
    "unproc_cbow_easy = (load_pickle_file(\"./unproc_results_CBOW_NAIVE_easy_best_params_[150, 256, 0.0001].p\"), \"CBOW Naive Unprocessed\")\n",
    "unproc_cbow_hard = (load_pickle_file(\"./unproc_results_CBOW_NAIVE_hard_best_params_[150, 256, 0.0001].p\"), \"CBOW Naive Unprocessed\")\n",
    "unproc_cbow_reg_easy = (load_pickle_file(\"./unproc_results_CBOW_REG_easy_best_params_[300, 256, 0.001].p\"), \"CBOW Regression Unprocessed\")\n",
    "unproc_cbow_reg_hard = (load_pickle_file(\"./unproc_results_CBOW_REG_hard_best_params_[300, 256, 0.001].p\"), \"CBOW Regression Unprocessed\")\n",
    "unproc_gru_easy = (load_pickle_file(\"./unproc_results_Fixed_GRU_easy_best_params_[300, 56, 0.0001].p\"), \"GRU Unprocessed\")\n",
    "unproc_gru_hard = (load_pickle_file(\"./unproc_results_Fixed_GRU_hard_best_params_[300, 56, 0.0001].p\"), \"GRU Unprocessed\")\n",
    "unproc_gru_reg_easy = (load_pickle_file(\"./unproc_results_GRUREG_easy_best_params_[350, 1024, 0.001].p\"), \"GRU Regression Unprocessed\")\n",
    "unproc_gru_reg_hard = (load_pickle_file(\"./unproc_results_GRUREG_hard_best_params_[350, 1024, 0.001].p\"), \"GRU Regression Unprocessed\")\n",
    "\n",
    "comparisons_easy = [cbow_easy, unproc_cbow_easy, cbow_reg_easy, unproc_cbow_reg_easy, gru_easy, unproc_gru_easy, gru_reg_easy, unproc_gru_reg_easy]\n",
    "comparisons_hard = [cbow_hard, unproc_cbow_hard, cbow_reg_hard, unproc_cbow_reg_hard, gru_hard, unproc_gru_hard, gru_reg_hard, unproc_gru_reg_hard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_for_key(lookup, key=\"top_1\"):\n",
    "    return pd.DataFrame(lookup[key])\n",
    "\n",
    "plt.figure()\n",
    "axes = None\n",
    "\n",
    "for file_tup in comparisons_easy:\n",
    "    file_df = create_df_for_key(file_tup[0])\n",
    "    if axes is None:\n",
    "        axes = file_df.plot(label=file_tup[1])\n",
    "    else:\n",
    "        file_df.plot(ax=axes, label=file_tup[1])\n",
    "        \n",
    "axes.set_xlabel(\"Epoch\")\n",
    "axes.set_ylabel(\"Accuracy Easy Dataset\")\n",
    "axes.legend([x[1] for x in comparisons_easy],loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "axes.set_ylim(0, 1.1)\n",
    "axes.set_xlim(0, 29)\n",
    "axes.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x+1:0.0f}\"))\n",
    "axes.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x*100:0.0f}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "axes = None\n",
    "\n",
    "for file_tup in comparisons_hard:\n",
    "    file_df = create_df_for_key(file_tup[0])\n",
    "    if axes is None:\n",
    "        axes = file_df.plot(label=file_tup[1])\n",
    "    else:\n",
    "        file_df.plot(ax=axes, label=file_tup[1])\n",
    "        \n",
    "axes.set_xlabel(\"Epoch\")\n",
    "axes.set_ylabel(\"Accuracy Hard Dataset\")\n",
    "axes.legend([x[1] for x in comparisons_hard],loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "axes.set_ylim(0, 1.1)\n",
    "axes.set_xlim(0, 29)\n",
    "axes.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x+1:0.0f}\"))\n",
    "axes.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x*100:0.0f}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unproc_cbow_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
